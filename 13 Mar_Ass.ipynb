{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe1d9ee3-9d31-460a-b2e4-b1ad70ca100c",
   "metadata": {},
   "source": [
    "## Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baaa58b-f923-4b90-9d3d-d1630867ed84",
   "metadata": {},
   "source": [
    "# Ans ==\n",
    "Analysis of Variance (ANOVA) is a statistical method used to compare means across multiple groups. However, ANOVA relies on several assumptions for its validity. Violations of these assumptions can impact the accuracy and reliability of the results. The key assumptions for ANOVA are:\n",
    "\n",
    "1. Normality: The data within each group should follow a normal distribution. If this assumption is violated, it may affect the accuracy of the p-values and confidence intervals associated with the ANOVA results.\n",
    "\n",
    "Example of violation: In a study comparing test scores across different teaching methods, if the scores within each teaching method group are not normally distributed, it may impact the validity of the ANOVA results.\n",
    "\n",
    "2. Homogeneity of Variances (Homoscedasticity): The variances of the populations being compared should be approximately equal. This assumption is important for the robustness of the F-test used in ANOVA.\n",
    "\n",
    "Example of violation: In a clinical trial comparing the effectiveness of different drug dosages, if the variances of the response variable (e.g., blood pressure reduction) are not similar across the dosage groups, it may lead to biased results.\n",
    "\n",
    "3. Independence of Observations: The observations within each group should be independent of each other. This means that the value of one observation should not be influenced by the value of another observation.\n",
    "\n",
    "Example of violation: In a study assessing the impact of a new teaching method on student performance, if the performance of one student is influenced by the performance of another (e.g., group discussions or collaborations), the independence assumption may be violated.\n",
    "\n",
    "4. Random Sampling: The data should be collected through a random sampling process. This ensures that the sample is representative of the population from which it is drawn.\n",
    "\n",
    "Example of violation: In a study comparing income levels across different regions, if the samples from each region are not randomly selected and instead biased towards certain income brackets, it may affect the generalizability of the ANOVA results.\n",
    "\n",
    "5. Interval or Ratio Scale Data: The dependent variable (the variable being measured) should be measured on an interval or ratio scale. ANOVA is not appropriate for categorical variables.\n",
    "\n",
    "Example of violation: Using ANOVA to compare mean scores across different ethnic groups based on a categorical variable (e.g., eye color) would be inappropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf6c633-8299-4c70-be84-83ad1fc1aea1",
   "metadata": {},
   "source": [
    "## Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b08dd4-6621-4c83-a4ba-d49f4df704ea",
   "metadata": {},
   "source": [
    "#  Ans ==\n",
    "Analysis of Variance (ANOVA) is a statistical technique that is used to compare means among three or more groups. There are three main types of ANOVA, each suitable for different situations:\n",
    "\n",
    "1. One-Way ANOVA:\n",
    "\n",
    "•Use Case: One-Way ANOVA is used when there is one independent variable (factor) with three or more levels (groups), and the goal is to compare the means of the dependent variable across these groups.\n",
    "\n",
    "•Example: Comparing the mean test scores of students taught using three different teaching methods.\n",
    "\n",
    "2. Two-Way ANOVA:\n",
    "\n",
    "•Use Case: Two-Way ANOVA is an extension of One-Way ANOVA, suitable when there are two independent variables (factors) influencing the dependent variable. It assesses the main effects of each factor as well as the interaction effect between them.\n",
    "\n",
    "•Example: Investigating the effects of both teaching method and gender on student test scores. Here, teaching method and gender are the two independent variables.\n",
    "\n",
    "3. Repeated Measures ANOVA:\n",
    "\n",
    "•Use Case: Repeated Measures ANOVA is used when measurements are taken on the same subjects or matched subjects over multiple time points or conditions. It is designed to assess changes within subjects over time or under different conditions.\n",
    "\n",
    "•Example: Evaluating the effect of a drug treatment on patients' blood pressure measured before treatment, during treatment, and after treatment for the same group of individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a3f4ad-d0b2-4de2-8615-1d8e96acd58f",
   "metadata": {},
   "source": [
    "## Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb48a273-6491-48a9-ae2f-6c15f66601a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ans ==\n",
    "The partitioning of variance in Analysis of Variance (ANOVA) refers to the process of decomposing the total variance observed in the data into different components that can be attributed to specific sources or factors. Understanding this concept is crucial for interpreting ANOVA results and gaining insights into the variability in the data.\n",
    "\n",
    "The total variance observed in a set of data can be broken down into three main components in the context of a one-way ANOVA:\n",
    "\n",
    "1. Between-Group Variance (SSB or SSBetween): This represents the variability between the group means. It indicates whether the means of the different groups are significantly different from each other. The larger the between-group variance relative to within-group variance, the more evidence there is for differences in group means.\n",
    "\n",
    "2. Within-Group Variance (SSW or SSWithin): This represents the variability within each group. It accounts for the individual differences and random variability within each group. A smaller within-group variance suggests that the observations within each group are more homogeneous.\n",
    "\n",
    "3. Total Variance (SST or SSTotal): This is the overall variability in the entire dataset, combining both the between-group and within-group variances. It is the sum of the squared differences between each individual data point and the overall mean.\n",
    "\n",
    "The key idea behind partitioning the variance is to compare the magnitudes of between-group variance and within-group variance to determine if the differences observed among the group means are statistically significant. This comparison is achieved by calculating the F-statistic, which is the ratio of between-group variance to within-group variance.\n",
    "\n",
    "If the between-group variance is significantly larger than the within-group variance, it suggests that the group means are likely different, and this provides evidence for rejecting the null hypothesis of equal means. On the other hand, if the within-group variance dominates, it suggests that the observed differences in group means are likely due to random variability, and there is insufficient evidence to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e36adde-6db9-419c-aa60-dbc5de8cc524",
   "metadata": {},
   "source": [
    "## Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605d1087-dca6-4c5e-aee1-8d62f9d217d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 349.3333333333333\n",
      "Explained Sum of Squares (SSE): 136.93333333333328\n",
      "Residual Sum of Squares (SSR): 212.40000000000003\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "group1 = np.array([12, 15, 18, 20, 22])\n",
    "group2 = np.array([8, 10, 14, 16, 20])\n",
    "group3 = np.array([5, 8, 10, 12, 15])\n",
    "\n",
    "all_data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "overall_mean = np.mean(all_data)\n",
    "\n",
    "sst = np.sum((all_data - overall_mean)**2)\n",
    "\n",
    "sse = np.sum([len(group) * (np.mean(group) - overall_mean)**2 for group in [group1, group2, group3]])\n",
    "\n",
    "ssr = np.sum((all_data - np.concatenate([np.mean(group) * np.ones_like(group) for group in [group1, group2, group3]]))**2)\n",
    "\n",
    "# Print the results\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea33c4f2-1dc9-4b48-b2e8-727ec05b7f06",
   "metadata": {},
   "source": [
    "## Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e981fcf4-9e5d-43d7-9d07-ac7cb52879e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Factor A (rows): 0.0\n",
      "Main Effect of Factor B (columns): 0.0\n",
      "Interaction Effect (AB Interaction): 0.0\n"
     ]
    }
   ],
   "source": [
    "#Ans ==\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = np.array([\n",
    "    [10, 12, 14],\n",
    "    [8, 11, 13],\n",
    "    [15, 18, 20],\n",
    "    [7, 10, 12]\n",
    "])\n",
    "\n",
    "\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "ME_A = np.mean(np.mean(data, axis=1) - overall_mean)\n",
    "\n",
    "ME_B = np.mean(np.mean(data, axis=0) - overall_mean)\n",
    "\n",
    "IE_AB = np.mean(data) - overall_mean - ME_A - ME_B\n",
    "\n",
    "# Print the results\n",
    "print(\"Main Effect of Factor A (rows):\", ME_A)\n",
    "print(\"Main Effect of Factor B (columns):\", ME_B)\n",
    "print(\"Interaction Effect (AB Interaction):\", IE_AB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700b23bd-0736-4c88-88be-c90a75b7a2b1",
   "metadata": {},
   "source": [
    "## Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee0598d-ff8e-445f-8dec-689c9f3c3a6a",
   "metadata": {},
   "source": [
    "# Ans ==\n",
    "In a one-way ANOVA, the F-statistic is used to test whether there are statistically significant differences among the means of the groups. The associated p-value indicates the probability of observing such extreme results by chance alone. Here's how you can interpret the results:\n",
    "\n",
    "1. F-Statistic:\n",
    "•The F-statistic in your case is 5.23.\n",
    "•The F-statistic is a ratio of the variance between groups to the variance within groups. A larger F-statistic suggests greater variability between group means relative to within-group variability.\n",
    "2. p-Value:\n",
    "•The p-value associated with the F-statistic is 0.02.\n",
    "•The p-value is the probability of observing an F-statistic as extreme as the one obtained, assuming the null hypothesis (that there are no differences between group means) is true.\n",
    "3. Interpretation:\n",
    "•If the p-value is less than the chosen significance level (commonly 0.05), you would reject the null hypothesis.\n",
    "•In this case, with a p-value of 0.02 (which is less than 0.05), you have statistical evidence to reject the null hypothesis\n",
    "4. Conclusion:\n",
    "•With a p-value of 0.02, you would conclude that there are statistically significant differences among the means of the groups.\n",
    "•In practical terms, this suggests that at least one group mean is different from the others\n",
    "5. Post-hoc Tests (if applicable):\n",
    "•If you have more than two groups, and the ANOVA indicates significant differences, you might perform post-hoc tests (e.g., Tukey's HSD, Bonferroni) to identify which specific groups differ from each other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9075e42-0bfd-41bd-b8a4-5b3611061435",
   "metadata": {},
   "source": [
    "## Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681c8dd6-336a-434e-b409-7cc19cfb23f7",
   "metadata": {},
   "source": [
    "# Ans ==\n",
    "Handling missing data in a repeated measures analysis of variance (ANOVA) is crucial to ensure the validity and reliability of the results. There are various methods to address missing data, each with its own advantages and potential consequences. Here are some common strategies:\n",
    "\n",
    "1. Complete Case Analysis (CCA): This approach involves analyzing only the cases with complete data for all variables. While this is straightforward, it may lead to a reduction in sample size and potentially biased results if the missing data are not missing completely at random (MCAR). CCA assumes that missing data do not depend on the unobserved values.\n",
    "\n",
    "2. Pairwise Deletion (or available case analysis): In this method, each analysis is conducted using all available data for each specific comparison. This approach allows the use of all available data but can lead to biased estimates if the missing data are not MCAR. The downside is that the analysis may produce different results depending on which pairs of measurements are used, making it difficult to interpret.\n",
    "\n",
    "3. Imputation Techniques: Imputation involves replacing missing values with estimated values. There are various imputation methods, including mean imputation, median imputation, regression imputation, and multiple imputation.\n",
    "\n",
    "    Mean/Median Imputation: This involves replacing missing values with the mean or median of the observed values for that variable. While       simple, it can lead to underestimation of variability and biased results, especially if the data are not missing completely at random.\n",
    "\n",
    "    Regression Imputation: This method involves predicting missing values based on the relationship with other variables. While it can            provide more accurate estimates, it assumes a linear relationship and may introduce bias if the relationship is not linear.\n",
    "\n",
    "      Multiple Imputation: This method creates multiple datasets with imputed values, each reflecting the uncertainty about the missing values. Analyses are then performed on each dataset, and the results are combined. Multiple imputation is considered a more sophisticated approach, providing more reliable estimates and standard errors.\n",
    "\n",
    "   Choosing the appropriate method depends on the nature of the missing data and the assumptions that can be reasonably made about the missingness mechanism. It's important to conduct sensitivity analyses to assess the robustness of the results to different imputation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3596105-c009-4c0e-9f76-c82addd5e7bf",
   "metadata": {},
   "source": [
    "## Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5e1abd-a096-4f7a-8ec5-1e48a19e6f11",
   "metadata": {},
   "source": [
    "# Ans ==\n",
    "Post-hoc tests are used after conducting an Analysis of Variance (ANOVA) to identify specific group differences when the overall ANOVA indicates that there is a significant difference between groups. Some common post-hoc tests include:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD):\n",
    "\n",
    "•When to use: Tukey's HSD is appropriate when you have more than two groups, and you want to compare all possible pairs of means.\n",
    "•Example: After conducting an ANOVA comparing the mean scores of three different teaching methods, Tukey's HSD can be used to determine which specific pairs of teaching methods differ significantly.\n",
    "\n",
    "2. Bonferroni Correction:\n",
    "\n",
    "•When to use: Bonferroni is suitable when you have multiple pairwise comparisons, and you want to control the overall Type I error rate.\n",
    "•Example: In a study comparing the mean performance of four different diets, if the ANOVA indicates a significant difference, Bonferroni correction can be applied to compare each pair of diets while controlling for the increased risk of Type I errors due to multiple comparisons.\n",
    "\n",
    "3. Scheffe's Test:\n",
    "\n",
    "•When to use: Scheffe's test is a conservative post-hoc test suitable for unequal sample sizes and various group comparisons.\n",
    "•Example: Suppose you are examining the average scores of students from five different schools with varying class sizes. If ANOVA suggests a significant difference, Scheffe's test can be applied to determine specific pairs of schools with significant differences in scores.\n",
    "\n",
    "4. Duncan's Multiple Range Test:\n",
    "\n",
    "•When to use: Duncan's test is appropriate when you have homogeneous variances and roughly equal sample sizes across groups.\n",
    "•Example: After performing an ANOVA on the average yields of five different fertilizer treatments in agriculture, Duncan's test can be used to identify which pairs of fertilizers result in significantly different yields.\n",
    "\n",
    "5. Holm's Method:\n",
    "\n",
    "•When to use: Holm's method is a step-down procedure suitable for controlling the familywise error rate.\n",
    "•Example: In a study comparing the mean reaction times of participants under different experimental conditions, if ANOVA reveals a significant difference, Holm's method can be applied to conduct multiple pairwise comparisons while controlling for the overall risk of Type I error.\n",
    "Example Scenario: Suppose a researcher conducts an ANOVA to compare the average scores of students exposed to three different study techniques. The ANOVA indicates a significant overall difference. To identify which specific pairs of study techniques result in significant differences in scores, the researcher might use Tukey's HSD to conduct all possible pairwise comparisons. This helps to pinpoint the differences between study techniques and guide further interpretation of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a79381-9950-472b-bb7d-53b0b42e45c6",
   "metadata": {},
   "source": [
    "## Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a74ecac5-104c-4bb9-9994-bc553f2a2531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 0.22346368715083784\n",
      "P-Value: 0.8010631449968824\n",
      "There is not enough evidence to reject the null hypothesis.\n",
      "There are no significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "diet_A = [1.5, 2.0, 1.8, 2.2, 1.6, 1.9, 1.7, 2.1, 1.5, 1.8, 2.0]  \n",
    "diet_B = [1.9, 2.1, 1.7, 2.5, 1.4, 1.6, 2.0, 1.8, 2.3, 1.5, 2.1]  \n",
    "diet_C = [1.6, 2.3, 1.5, 2.0, 1.8, 2.2, 1.9, 1.7, 2.1, 1.4, 1.6]  \n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Report the results\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "if p_value < 0.05:\n",
    "    print(\"There is significant evidence to reject the null hypothesis.\")\n",
    "    print(\"There are significant differences between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"There is not enough evidence to reject the null hypothesis.\")\n",
    "    print(\"There are no significant differences between the mean weight loss of the three diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8810aa-410a-4000-b6d1-04390a7e7780",
   "metadata": {},
   "source": [
    "## Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5190b4db-e8a3-4d76-a528-77992f83b97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            df       sum_sq    mean_sq         F    PR(>F)\n",
      "C(Program)                 2.0    15.717327   7.858664  0.344485  0.709581\n",
      "C(Experience)              1.0     2.994142   2.994142  0.131248  0.718051\n",
      "C(Program):C(Experience)   2.0     9.952457   4.976229  0.218133  0.804472\n",
      "Residual                  84.0  1916.273490  22.812780       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "n_employees_per_group = 30\n",
    "programs = np.repeat(['A', 'B', 'C'], n_employees_per_group)\n",
    "experience_levels = np.tile(['novice', 'experienced'], n_employees_per_group * 3 // 2)\n",
    "task_completion_times = np.random.normal(loc=20, scale=5, size=n_employees_per_group * 3)\n",
    "\n",
    "data = pd.DataFrame({'Program': programs, 'Experience': experience_levels, 'Time': task_completion_times})\n",
    "\n",
    "formula = 'Time ~ C(Program) + C(Experience) + C(Program):C(Experience)'\n",
    "model = ols(formula, data).fit()\n",
    "anova_results = anova_lm(model)\n",
    "\n",
    "print(anova_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fcceaa-3383-4370-9a74-764939a0f35c",
   "metadata": {},
   "source": [
    "## Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "915723f4-5e44-4813-b91b-ab4ff332c04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test: t-statistic = -4.108723928204809, p-value = 8.261945608702611e-05\n",
      "The difference in test scores between the two groups is statistically significant.\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      " group1    group2    meandiff p-adj  lower   upper  reject\n",
      "----------------------------------------------------------\n",
      "Control Experimental   7.4325 0.0001 3.8427 11.0224   True\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "np.random.seed(42) \n",
    "control_group_scores = np.random.normal(loc=70, scale=10, size=50)\n",
    "experimental_group_scores = np.random.normal(loc=75, scale=10, size=50)\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(control_group_scores, experimental_group_scores)\n",
    "\n",
    "print(f'Two-sample t-test: t-statistic = {t_stat}, p-value = {p_value}')\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print('The difference in test scores between the two groups is statistically significant.')\n",
    "else:\n",
    "    print('There is no statistically significant difference in test scores between the two groups.')\n",
    "\n",
    "all_scores = np.concatenate([control_group_scores, experimental_group_scores])\n",
    "group_labels = ['Control'] * len(control_group_scores) + ['Experimental'] * len(experimental_group_scores)\n",
    "\n",
    "tukey_results = pairwise_tukeyhsd(all_scores, group_labels, alpha=0.05)\n",
    "\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020f283b-52e0-4d28-9ea7-95ff1e40e951",
   "metadata": {},
   "source": [
    "## Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9145d54-a417-4ebc-82f6-67a6068d8eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store  0.2176 2.0000 58.0000 0.8051\n",
      "===================================\n",
      "\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      " group1  group2 meandiff p-adj   lower  upper  reject\n",
      "-----------------------------------------------------\n",
      "Store_A Store_B  -1.0827  0.904  -7.112 4.9466  False\n",
      "Store_A Store_C  -1.6679 0.7874 -7.6972 4.3614  False\n",
      "Store_B Store_C  -0.5852 0.9709 -6.6145 5.4441  False\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate sample data (replace this with your actual data)\n",
    "np.random.seed(42)\n",
    "days = np.arange(1, 31)\n",
    "store_a = np.random.normal(50, 10, 30)\n",
    "store_b = np.random.normal(55, 12, 30)\n",
    "store_c = np.random.normal(48, 8, 30)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Day': np.repeat(days, 3),  # Repeat days for each store\n",
    "    'Store': np.tile(['Store_A', 'Store_B', 'Store_C'], 30),\n",
    "    'Sales': np.concatenate([store_a, store_b, store_c])\n",
    "})\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "model = ols('Sales ~ Store', data=data).fit()\n",
    "anova_results = AnovaRM(data, 'Sales', 'Day', within=['Store']).fit()\n",
    "\n",
    "print(anova_results)\n",
    "\n",
    "# Perform post-hoc test (Tukey's HSD)\n",
    "posthoc = pairwise_tukeyhsd(data['Sales'], data['Store'])\n",
    "print(posthoc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f3f692-7965-4625-ae3a-78a3d45c5873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
